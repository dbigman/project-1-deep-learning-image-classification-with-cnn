{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "### Evaluate on Validation/Test Set\n",
    "- **Compute Metrics:**  \n",
    "  Calculate accuracy, precision, recall, and F1-score (using libraries like scikit-learn).\n",
    "- **Generate Classification Report:**  \n",
    "  Provide detailed per-class performance metrics.\n",
    "\n",
    "### Confusion Matrix\n",
    "- **Visualization:**  \n",
    "  Use seaborn’s `heatmap` or similar tools to plot the confusion matrix.\n",
    "- **Analysis:**  \n",
    "  Identify classes where the model performs well or struggles.\n",
    "\n",
    "### Performance Analysis\n",
    "- **Overfitting/Underfitting Check:**  \n",
    "  Compare training and validation metrics.\n",
    "- **Adjustments:**  \n",
    "  Consider regularization techniques or architectural changes if necessary.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define file paths for the validation and test TFRecord files\n",
    "val_tfrecord = \"balanced_val_20250220_235108.tfrecord\"\n",
    "test_tfrecord = \"balanced_test_20250220_235108.tfrecord\"\n",
    "\n",
    "# Define a parsing function for the TFRecord files\n",
    "feature_description = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    # Decode JPEG image, resize to 150x150 and normalize to [0, 1]\n",
    "    image = tf.io.decode_jpeg(parsed['image'], channels=3)\n",
    "    image = tf.image.resize(image, [150, 150])\n",
    "    image = image / 255.0\n",
    "    label = tf.cast(parsed['label'], tf.int32)\n",
    "    return image, label\n",
    "\n",
    "# Set up dataset parameters\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Create the validation dataset\n",
    "val_dataset = tf.data.TFRecordDataset(val_tfrecord) \\\n",
    "    .map(_parse_function, num_parallel_calls=AUTOTUNE) \\\n",
    "    .batch(BATCH_SIZE) \\\n",
    "    .prefetch(AUTOTUNE)\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = tf.data.TFRecordDataset(test_tfrecord) \\\n",
    "    .map(_parse_function, num_parallel_calls=AUTOTUNE) \\\n",
    "    .batch(BATCH_SIZE) \\\n",
    "    .prefetch(AUTOTUNE)\n",
    "\n",
    "# Load the best saved model (using the native Keras format)\n",
    "model = load_model('best_trained_model.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Validation/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 193ms/step - accuracy: 0.3632 - loss: 3.2622\n",
      "Validation Loss: 3.3417835235595703\n",
      "Validation Accuracy: 0.35297131538391113\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 204ms/step - accuracy: 0.3494 - loss: 3.1629\n",
      "Test Loss: 3.16951322555542\n",
      "Test Accuracy: 0.3490733802318573\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_dataset)\n",
    "print(\"Validation Loss:\", val_loss)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Initialize lists to collect true labels and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Loop over the test dataset (assuming test_dataset is already defined)\n",
    "for images, labels in test_dataset:\n",
    "    # Get model predictions (the output is probability for each class)\n",
    "    preds = model.predict(images)\n",
    "    # Convert predictions to class labels by taking the argmax\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    \n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(preds)\n",
    "\n",
    "# Convert lists to numpy arrays for metric computations\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test Precision: {:.4f}\".format(precision))\n",
    "print(\"Test Recall: {:.4f}\".format(recall))\n",
    "print(\"Test F1 Score: {:.4f}\".format(f1))\n",
    "\n",
    "# Assuming you have a list of class names from your dataset\n",
    "# For example, class_names = ['cat', 'dog', 'elephant', ...]\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
